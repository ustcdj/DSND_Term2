{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Variables\n",
    "\n",
    "One of the main ways for working with categorical variables is using 0, 1 encodings.  In this technique, you create a new column for every level of the categorical variable.  The **advantages** of this approach include:\n",
    "\n",
    "1. The ability to have differing influences of each level on the response.\n",
    "2. You do not impose a rank of the categories.\n",
    "3. The ability to interpret the results more easily than other encodings.\n",
    "\n",
    "The **disadvantages** of this approach are that you introduce a large number of effects into your model.  If you have a large number of categorical variables or categorical variables with a large number of levels, but not a large sample size, you might not be able to estimate the impact of each of these variables on your response variable.  There are some rules of thumb that suggest 10 data points for each variable you add to your model.  That is 10 rows for each column.  This is a reasonable lower bound, but the larger your sample (assuming it is representative), the better.\n",
    "\n",
    "Let's try out adding dummy variables for the categorical variables into the model.  We will compare to see the improvement over the original model only using quantitative variables.  \n",
    "\n",
    "\n",
    "#### Run the cell below to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The r-squared score for the model using only quantitative variables was 0.03257139063404435 on 1503 values.'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import test1 as t\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('./survey_results_public.csv')\n",
    "df.head()\n",
    "\n",
    "#Only use quant variables and drop any rows with missing values\n",
    "num_vars = df[['Salary', 'CareerSatisfaction', 'HoursPerWeek', 'JobSatisfaction', 'StackOverflowSatisfaction']]\n",
    "\n",
    "#Drop the rows with missing salaries\n",
    "drop_sal_df = num_vars.dropna(subset=['Salary'], axis=0)\n",
    "\n",
    "# Mean function\n",
    "fill_mean = lambda col: col.fillna(col.mean())\n",
    "# Fill the mean\n",
    "fill_df = drop_sal_df.apply(fill_mean, axis=0)\n",
    "\n",
    "#Split into explanatory and response variables\n",
    "X = fill_df[['CareerSatisfaction', 'HoursPerWeek', 'JobSatisfaction', 'StackOverflowSatisfaction']]\n",
    "y = fill_df['Salary']\n",
    "\n",
    "#Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state=42) \n",
    "\n",
    "lm_model = LinearRegression(normalize=True) # Instantiate\n",
    "lm_model.fit(X_train, y_train) #Fit\n",
    "        \n",
    "#Predict and score the model\n",
    "y_test_preds = lm_model.predict(X_test) \n",
    "\"The r-squared score for the model using only quantitative variables was {} on {} values.\".format(r2_score(y_test, y_test_preds), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19102, 154)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "\n",
    "**1.** Use the **df** dataframe. Identify the columns that are categorical in nature.  How many of the columns are considered categorical?  Use the reference [here](http://pbpython.com/categorical-encoding.html) if you get stuck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## df.dtypes[df.dtypes != 'object']\n",
    "## df.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "cat_df = df.select_dtypes(include=['object'])\n",
    "# Subset to a dataframe only holding the categorical columns\n",
    "\n",
    "# Print how many categorical columns are in the dataframe - should be 147\n",
    "cat_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Professional</th>\n",
       "      <th>ProgramHobby</th>\n",
       "      <th>Country</th>\n",
       "      <th>University</th>\n",
       "      <th>EmploymentStatus</th>\n",
       "      <th>FormalEducation</th>\n",
       "      <th>MajorUndergrad</th>\n",
       "      <th>HomeRemote</th>\n",
       "      <th>CompanySize</th>\n",
       "      <th>CompanyType</th>\n",
       "      <th>...</th>\n",
       "      <th>StackOverflowBetter</th>\n",
       "      <th>StackOverflowWhatDo</th>\n",
       "      <th>StackOverflowMakeMoney</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HighestEducationParents</th>\n",
       "      <th>Race</th>\n",
       "      <th>SurveyLong</th>\n",
       "      <th>QuestionsInteresting</th>\n",
       "      <th>QuestionsConfusing</th>\n",
       "      <th>InterestedAnswers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Student</td>\n",
       "      <td>Yes, both</td>\n",
       "      <td>United States</td>\n",
       "      <td>No</td>\n",
       "      <td>Not employed, and not looking for work</td>\n",
       "      <td>Secondary school</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Strongly disagree</td>\n",
       "      <td>Male</td>\n",
       "      <td>High school</td>\n",
       "      <td>White or of European descent</td>\n",
       "      <td>Strongly disagree</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>Strongly agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Student</td>\n",
       "      <td>Yes, both</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Yes, full-time</td>\n",
       "      <td>Employed part-time</td>\n",
       "      <td>Some college/university study without earning ...</td>\n",
       "      <td>Computer science or software engineering</td>\n",
       "      <td>More than half, but not all, the time</td>\n",
       "      <td>20 to 99 employees</td>\n",
       "      <td>Privately-held limited company, not in startup...</td>\n",
       "      <td>...</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Strongly disagree</td>\n",
       "      <td>Male</td>\n",
       "      <td>A master's degree</td>\n",
       "      <td>White or of European descent</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>Strongly agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Professional developer</td>\n",
       "      <td>Yes, both</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed full-time</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>Computer science or software engineering</td>\n",
       "      <td>Less than half the time, but at least one day ...</td>\n",
       "      <td>10,000 or more employees</td>\n",
       "      <td>Publicly-traded corporation</td>\n",
       "      <td>...</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>Male</td>\n",
       "      <td>A professional degree</td>\n",
       "      <td>White or of European descent</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>Agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Professional non-developer who sometimes write...</td>\n",
       "      <td>Yes, both</td>\n",
       "      <td>United States</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed full-time</td>\n",
       "      <td>Doctoral degree</td>\n",
       "      <td>A non-computer-focused engineering discipline</td>\n",
       "      <td>Less than half the time, but at least one day ...</td>\n",
       "      <td>10,000 or more employees</td>\n",
       "      <td>Non-profit/non-governmental organization or pr...</td>\n",
       "      <td>...</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>Male</td>\n",
       "      <td>A doctoral degree</td>\n",
       "      <td>White or of European descent</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Strongly agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Professional developer</td>\n",
       "      <td>Yes, I program as a hobby</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed full-time</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Computer science or software engineering</td>\n",
       "      <td>Never</td>\n",
       "      <td>10 to 19 employees</td>\n",
       "      <td>Privately-held limited company, not in startup...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Professional  \\\n",
       "0                                            Student   \n",
       "1                                            Student   \n",
       "2                             Professional developer   \n",
       "3  Professional non-developer who sometimes write...   \n",
       "4                             Professional developer   \n",
       "\n",
       "                ProgramHobby         Country      University  \\\n",
       "0                  Yes, both   United States              No   \n",
       "1                  Yes, both  United Kingdom  Yes, full-time   \n",
       "2                  Yes, both  United Kingdom              No   \n",
       "3                  Yes, both   United States              No   \n",
       "4  Yes, I program as a hobby     Switzerland              No   \n",
       "\n",
       "                         EmploymentStatus  \\\n",
       "0  Not employed, and not looking for work   \n",
       "1                      Employed part-time   \n",
       "2                      Employed full-time   \n",
       "3                      Employed full-time   \n",
       "4                      Employed full-time   \n",
       "\n",
       "                                     FormalEducation  \\\n",
       "0                                   Secondary school   \n",
       "1  Some college/university study without earning ...   \n",
       "2                                  Bachelor's degree   \n",
       "3                                    Doctoral degree   \n",
       "4                                    Master's degree   \n",
       "\n",
       "                                  MajorUndergrad  \\\n",
       "0                                            NaN   \n",
       "1       Computer science or software engineering   \n",
       "2       Computer science or software engineering   \n",
       "3  A non-computer-focused engineering discipline   \n",
       "4       Computer science or software engineering   \n",
       "\n",
       "                                          HomeRemote  \\\n",
       "0                                                NaN   \n",
       "1              More than half, but not all, the time   \n",
       "2  Less than half the time, but at least one day ...   \n",
       "3  Less than half the time, but at least one day ...   \n",
       "4                                              Never   \n",
       "\n",
       "                CompanySize  \\\n",
       "0                       NaN   \n",
       "1        20 to 99 employees   \n",
       "2  10,000 or more employees   \n",
       "3  10,000 or more employees   \n",
       "4        10 to 19 employees   \n",
       "\n",
       "                                         CompanyType  ... StackOverflowBetter  \\\n",
       "0                                                NaN  ...      Strongly agree   \n",
       "1  Privately-held limited company, not in startup...  ...      Strongly agree   \n",
       "2                        Publicly-traded corporation  ...               Agree   \n",
       "3  Non-profit/non-governmental organization or pr...  ...               Agree   \n",
       "4  Privately-held limited company, not in startup...  ...                 NaN   \n",
       "\n",
       "  StackOverflowWhatDo StackOverflowMakeMoney Gender HighestEducationParents  \\\n",
       "0      Strongly agree      Strongly disagree   Male             High school   \n",
       "1      Strongly agree      Strongly disagree   Male       A master's degree   \n",
       "2               Agree               Disagree   Male   A professional degree   \n",
       "3      Strongly agree               Disagree   Male       A doctoral degree   \n",
       "4                 NaN                    NaN    NaN                     NaN   \n",
       "\n",
       "                           Race         SurveyLong QuestionsInteresting  \\\n",
       "0  White or of European descent  Strongly disagree       Strongly agree   \n",
       "1  White or of European descent     Somewhat agree       Somewhat agree   \n",
       "2  White or of European descent     Somewhat agree                Agree   \n",
       "3  White or of European descent              Agree                Agree   \n",
       "4                           NaN                NaN                  NaN   \n",
       "\n",
       "  QuestionsConfusing InterestedAnswers  \n",
       "0           Disagree    Strongly agree  \n",
       "1           Disagree    Strongly agree  \n",
       "2           Disagree             Agree  \n",
       "3     Somewhat agree    Strongly agree  \n",
       "4                NaN               NaN  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19102, 147)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.cat_df_check?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That wasn't quite as expected.  The input cat_df variable should be a dataframe of all of the categorical variables.  You can use select_dtypes to select the 'object' data type.\n"
     ]
    }
   ],
   "source": [
    "# Test your dataframe matches the solution\n",
    "t.cat_df_check(cat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "\n",
    "**2.** Use **cat_df** and the cells below to fill in the dictionary below the correct value for each statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df.isnull().mean()[cat_df.isnull().mean() > 0.75].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a2bc55bf88>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAOQElEQVR4nO3df4xl9VnH8fdTtggyLUu7OCELdmi6bbphoi0TxDTRGWgNsgb4Aw2E1sWsbtpa06RrdLWJ8WeyNaEYExLdCHY12gGxLRvAGKSMaAPUXaEMP1KhuOIC2bUpu3EQazd9/OMeNpNhdu/ZO/fHPDvvVzLZc849Z87z7D372TPnnu+ZyEwkSfW8ZdQFSJJ6Y4BLUlEGuCQVZYBLUlEGuCQVtW6YO9uwYUNOTEz0tO1rr73GOeec09+CCrDvtcW+15a2fe/fv//bmXn+0uVDDfCJiQn27dvX07Zzc3NMT0/3t6AC7Httse+1pW3fEfEfyy33EookFWWAS1JRBrgkFWWAS1JRBrgkFWWAS1JRBrgkFWWAS1JRBrgkFTXUkZiqYWLnfSPb94FdW0a2b6kaz8AlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKKah3gEXFGRDweEfc28xdHxGMR8VxE3BkRZw6uTEnSUqdyBv5p4NlF858Dbs3MTcCrwLZ+FiZJOrlWAR4RFwJbgD9r5gO4Ari7WWUPcN0gCpQkLa/tGfgfAb8GfL+ZfydwJDOPNfMHgY19rk2SdBKRmSdfIeJngKsz85MRMQ38KvALwCOZ+Z5mnYuA+zNzcpnttwPbAcbHxy+dnZ3tqdCFhQXGxsZ62rayUfQ9/9LRoe5vscmN5wK+32uNfZ/czMzM/sycWrq8ze/E/BBwTURcDZwFvJ3OGfn6iFjXnIVfCLy83MaZuRvYDTA1NZXT09Mtdvlmc3Nz9LptZaPo++ZR/k7Mm6YB3++1xr570/USSmb+RmZemJkTwA3AVzPzJuAh4Ppmta3APT1XIUk6ZSu5D/zXgc9ExPN0ronf3p+SJElttLmEclxmzgFzzfQLwGX9L0mS1IYjMSWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckoo6pV+pJp2uJnbeN7J9H9i1ZWT7Vm2egUtSUQa4JBVlgEtSUQa4JBVlgEtSUQa4JBVlgEtSUQa4JBXlQB6tKm8MqNkxeYybRzi4RqrAM3BJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiugZ4RJwVEV+PiG9ExNMR8TvN8osj4rGIeC4i7oyIMwdfriTpDW3OwL8LXJGZPwL8KHBVRFwOfA64NTM3Aa8C2wZXpiRpqa4Bnh0Lzexbm68ErgDubpbvAa4bSIWSpGW1ugYeEWdExBPAYeAB4FvAkcw81qxyENg4mBIlScuJzGy/csR64MvAbwF/npnvaZZfBNyfmZPLbLMd2A4wPj5+6ezsbE+FLiwsMDY21tO2lY2i7/mXjg51f8sZPxsOvT7qKoZjcuO5x6c9zteWtn3PzMzsz8yppctP6XngmXkkIuaAy4H1EbGuOQu/EHj5BNvsBnYDTE1N5fT09Kns8ri5uTl63bayUfS9Gp7DvWPyGLfMr43H1R+4afr4tMf52rLSvtvchXJ+c+ZNRJwNfBh4FngIuL5ZbStwT89VSJJOWZtTnAuAPRFxBp3Avysz742IZ4DZiPh94HHg9gHWKUlaomuAZ+aTwAeWWf4CcNkgipIkdedITEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqqmuAR8RFEfFQRDwbEU9HxKeb5e+IiAci4rnmz/MGX64k6Q1tzsCPATsy8/3A5cAvR8RmYCfwYGZuAh5s5iVJQ9I1wDPzlcz812b6v4FngY3AtcCeZrU9wHWDKlKS9GaRme1XjpgAHgYuAV7MzPWLXns1M990GSUitgPbAcbHxy+dnZ3tqdCFhQXGxsZ62rayUfQ9/9LRoe5vOeNnw6HXR13FcExuPPf4tMf52tK275mZmf2ZObV0eesAj4gx4B+BP8jML0XEkTYBvtjU1FTu27ev1f6WmpubY3p6uqdtKxtF3xM77xvq/pazY/IYt8yvG3UZQ3Fg15bj0x7na0vbviNi2QBvdRdKRLwV+FvgrzLzS83iQxFxQfP6BcDhtkVLklauzV0oAdwOPJuZn1/00l5gazO9Fbin/+VJkk6kzc+oHwI+BsxHxBPNst8EdgF3RcQ24EXgZwdToiRpOV0DPDP/GYgTvHxlf8uRJLXlSExJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKmrdqAuQpGGZ2HnfSPZ7YNeWgXxfz8AlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKK6hrgEXFHRByOiKcWLXtHRDwQEc81f5432DIlSUu1OQP/AnDVkmU7gQczcxPwYDMvSRqirgGemQ8D31my+FpgTzO9B7iuz3VJkrqIzOy+UsQEcG9mXtLMH8nM9YtefzUzl72MEhHbge0A4+Pjl87OzvZU6MLCAmNjYz1tW9ko+p5/6ehQ97ec8bPh0OujrmI4Jjeee3za43ywRnVsL36PF2vb98zMzP7MnFq6fOBD6TNzN7AbYGpqKqenp3v6PnNzc/S6bWWj6PvmEQ03XmzH5DFumV8bT3o4cNP08WmP88Ea1bG9+D1ebKV993oXyqGIuACg+fNwzxVIknrSa4DvBbY201uBe/pTjiSprTa3EX4ReAR4X0QcjIhtwC7gIxHxHPCRZl6SNERdLzJm5o0neOnKPtciSToFjsSUpKIMcEkqygCXpKLK3Gg7/9LRkdzDOahfhSRJK+UZuCQVZYBLUlEGuCQVZYBLUlFlPsRciyZ23seOyWOr4uFSklYfz8AlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqSifRtjFhE8ClLRKeQYuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAN5pBFbPFhsx+Qxbl4Dg8cO7Noy6hJOC56BS1JRBrgkFWWAS1JRBrgkFWWAS1JRBrgkFbWiAI+IqyLimxHxfETs7FdRkqTueg7wiDgDuA34aWAzcGNEbO5XYZKkk1vJGfhlwPOZ+UJm/h8wC1zbn7IkSd1EZva2YcT1wFWZ+YvN/MeAH8vMTy1ZbzuwvZl9H/DNHmvdAHy7x20rs++1xb7XlrZ9vyszz1+6cCVD6WOZZW/63yAzdwO7V7Cfzs4i9mXm1Eq/TzX2vbbY99qy0r5XcgnlIHDRovkLgZdX8P0kSadgJQH+L8CmiLg4Is4EbgD29qcsSVI3PV9CycxjEfEp4O+BM4A7MvPpvlX2Ziu+DFOUfa8t9r22rKjvnj/ElCSNliMxJakoA1ySilp1Ad5teH5E/EBE3Nm8/lhETAy/yv5r0fdnIuKZiHgyIh6MiHeNos5+a/s4hoi4PiIyIk6LW83a9B0RP9e8509HxF8Pu8ZBaHGc/3BEPBQRjzfH+tWjqLOfIuKOiDgcEU+d4PWIiD9u/k6ejIgPtv7mmblqvuh8GPot4N3AmcA3gM1L1vkk8CfN9A3AnaOue0h9zwA/2Ex/Yq303az3NuBh4FFgatR1D+n93gQ8DpzXzP/QqOseUt+7gU8005uBA6Ouuw99/wTwQeCpE7x+NfB3dMbWXA481vZ7r7Yz8DbD868F9jTTdwNXRsRyg4oq6dp3Zj6Umf/TzD5K57776to+juH3gD8E/neYxQ1Qm75/CbgtM18FyMzDQ65xENr0ncDbm+lzOQ3GlmTmw8B3TrLKtcBfZMejwPqIuKDN915tAb4R+M9F8webZcuuk5nHgKPAO4dS3eC06XuxbXT+x66ua98R8QHgosy8d5iFDVib9/u9wHsj4msR8WhEXDW06ganTd+/DXw0Ig4C9wO/MpzSRupU//0ft9p+K32b4fmthvAX07qniPgoMAX85EArGo6T9h0RbwFuBW4eVkFD0ub9XkfnMso0nZ+2/ikiLsnMIwOubZDa9H0j8IXMvCUifhz4y6bv7w++vJHpOdNW2xl4m+H5x9eJiHV0fsw62Y8nFbR6LEFEfBj4LHBNZn53SLUNUre+3wZcAsxFxAE61wf3ngYfZLY9zu/JzO9l5r/TeQjcpiHVNyht+t4G3AWQmY8AZ9F54NPprOfHkqy2AG8zPH8vsLWZvh74ajafBBTWte/mUsKf0gnv0+F6KHTpOzOPZuaGzJzIzAk61/6vycx9oym3b9oc51+h88E1EbGBziWVF4ZaZf+16ftF4EqAiHg/nQD/r6FWOXx7gZ9v7ka5HDiama+02nLUn9Ce4BPZf6PzafVnm2W/S+cfLnTe0L8Bnge+Drx71DUPqe9/AA4BTzRfe0dd8zD6XrLuHKfBXSgt3+8APg88A8wDN4y65iH1vRn4Gp07VJ4AfmrUNfeh5y8CrwDfo3O2vQ34OPDxRe/1bc3fyfypHOMOpZekolbbJRRJUksGuCQVZYBLUlEGuCQVZYBLUlEGuCQVZYBLUlH/D1DQDyidBM08AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell for your work here\n",
    "cat_df.isnull().mean().hist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oops! One or more of those doesn't look quite right.  Each value should be an integer corresponding to the number of columns described.\n"
     ]
    }
   ],
   "source": [
    "# Provide the key as an `integer` that answers the question\n",
    "\n",
    "cat_df_dict = {'the number of columns with no missing values': 6, \n",
    "               'the number of columns with more than half of the column missing': 49,\n",
    "               'the number of columns with more than 75% of the column missing': 13\n",
    "}\n",
    "\n",
    "# Check your dictionary results\n",
    "t.cat_df_dict_check(cat_df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "\n",
    "**3.** For each of the categorical variables, we now need to create dummy columns.  However, as we saw above, there are a lot of missing values in the current set of categorical columns.  So, you might be wondering, what happens when you dummy a column that has missing values.\n",
    "\n",
    "The documentation for creating dummy variables in pandas is available [here](http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.get_dummies.html), but we can also just put this to practice to see what happens.\n",
    "\n",
    "First, run the cell below to create a dataset that you will use before moving to the full stackoverflow data.\n",
    "\n",
    "After you have created **dummy_var_df**, use the additional cells to fill in the **sol_3_dict** with the correct variables that match each key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>b</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col1  col2\n",
       "0    a   1.0\n",
       "1    a   NaN\n",
       "2    b   3.0\n",
       "3    b   NaN\n",
       "4    a   5.0\n",
       "5  NaN   6.0\n",
       "6    b   7.0\n",
       "7  NaN   8.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_var_df = pd.DataFrame({'col1': ['a', 'a', 'b', 'b', 'a', np.nan, 'b', np.nan],\n",
    "                             'col2': [1, np.nan, 3, np.nan, 5, 6, 7, 8] \n",
    "})\n",
    "                            \n",
    "dummy_var_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "0  1  0\n",
       "1  1  0\n",
       "2  0  1\n",
       "3  0  1\n",
       "4  1  0\n",
       "5  0  0\n",
       "6  0  1\n",
       "7  0  0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(dummy_var_df['col1'])# Use this cell to write whatever code you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice job! That looks right to me!\n"
     ]
    }
   ],
   "source": [
    "a = 1\n",
    "b = 2\n",
    "c = 3\n",
    "d = 'col1'\n",
    "e = 'col2'\n",
    "f = 'the rows with NaNs are dropped by default'\n",
    "g = 'the NaNs are always encoded as 0'\n",
    "\n",
    "\n",
    "sol_3_dict = {'Which column should you create a dummy variable for?': d,\n",
    "              'When you use the default settings for creating dummy variables, how many are created?': 2,\n",
    "              'What happens with the nan values?': g \n",
    "             }\n",
    "\n",
    "# Check your dictionary against the solution\n",
    "t.sol_3_dict_check(sol_3_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "\n",
    "**4.** Notice, you can also use **get_dummies** to encode **NaN** values as their own dummy coded column using the **dummy_na** argument.  Often these NaN values are also informative, but you are not capturing them by leaving them as 0 in every column of your model.\n",
    "\n",
    "Create a new encoding for **col1** of **dummy_var_df** that provides dummy columns not only for each level, but also for the missing values below. Store the 3 resulting dummy columns in **dummy_cols_df** and check your solution against ours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  NaN\n",
       "0  1  0    0\n",
       "1  1  0    0\n",
       "2  0  1    0\n",
       "3  0  1    0\n",
       "4  1  0    0\n",
       "5  0  0    1\n",
       "6  0  1    0\n",
       "7  0  0    1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_cols_df = pd.get_dummies(dummy_var_df['col1'], dummy_na=True)\n",
    "#Create the three dummy columns for dummy_var_df\n",
    "\n",
    "# Look at your result\n",
    "dummy_cols_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice job! That looks right!\n"
     ]
    }
   ],
   "source": [
    "# Check against the solution\n",
    "t.dummy_cols_df_check(dummy_cols_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5\n",
    "\n",
    "**5.** We could use either of the above to begin creating an X matrix that would (potentially) allow us to predict better than just the numeric columns we have been using thus far.\n",
    "\n",
    "First, complete the **create_dummy_df**.  Follow the instructions in the document string to assist as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a copy of the dataframe\n",
    "cat_df_copy = cat_df.copy()\n",
    "\n",
    "#Pull a list of the column names of the categorical variables\n",
    "cat_cols_lst = cat_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_df(df, cat_cols, dummy_na):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with categorical variables you want to dummy\n",
    "    cat_cols - list of strings that are associated with names of the categorical columns\n",
    "    dummy_na - Bool holding whether you want to dummy NA vals of categorical columns or not\n",
    "    \n",
    "    OUTPUT:\n",
    "    df - a new dataframe that has the following characteristics:\n",
    "            1. contains all columns that were not specified as categorical\n",
    "            2. removes all the original columns in cat_cols\n",
    "            3. dummy columns for each of the categorical columns in cat_cols\n",
    "            4. if dummy_na is True - it also contains dummy columns for the NaN values\n",
    "            5. Use a prefix of the column name with an underscore (_) for separating \n",
    "    '''\n",
    "    df_cat = df[cat_cols]\n",
    "    df_num = df.drop(columns=cat_cols, axis=1)\n",
    "    df_cat_dummy = pd.get_dummies(df_cat, prefix=cat_cols, prefix_sep='_', dummy_na=dummy_na, columns=cat_cols, drop_first=True)\n",
    "    df = pd.concat([df_num, df_cat_dummy], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5009, 11938)\n"
     ]
    }
   ],
   "source": [
    "df.dropna(axis=0, how='any', subset=['Salary'], inplace=True)\n",
    "df_new = create_dummy_df(df, cat_cols_lst, dummy_na=False) #Use your newly created function\n",
    "\n",
    "# Show shape to assure it has a shape of (5009, 11938)\n",
    "print(df_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Respondent</th>\n",
       "      <th>CareerSatisfaction</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>HoursPerWeek</th>\n",
       "      <th>StackOverflowSatisfaction</th>\n",
       "      <th>Salary</th>\n",
       "      <th>ExpectedSalary</th>\n",
       "      <th>ProgramHobby_Yes, I contribute to open source projects</th>\n",
       "      <th>ProgramHobby_Yes, I program as a hobby</th>\n",
       "      <th>ProgramHobby_Yes, both</th>\n",
       "      <th>...</th>\n",
       "      <th>QuestionsInteresting_Strongly agree</th>\n",
       "      <th>QuestionsInteresting_Strongly disagree</th>\n",
       "      <th>QuestionsConfusing_Disagree</th>\n",
       "      <th>QuestionsConfusing_Somewhat agree</th>\n",
       "      <th>QuestionsConfusing_Strongly agree</th>\n",
       "      <th>QuestionsConfusing_Strongly disagree</th>\n",
       "      <th>InterestedAnswers_Disagree</th>\n",
       "      <th>InterestedAnswers_Somewhat agree</th>\n",
       "      <th>InterestedAnswers_Strongly agree</th>\n",
       "      <th>InterestedAnswers_Strongly disagree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113750.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100764.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11938 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Respondent  CareerSatisfaction  JobSatisfaction  HoursPerWeek  \\\n",
       "2            3                 8.0              9.0           NaN   \n",
       "14          15                 8.0              8.0           NaN   \n",
       "17          18                 9.0              8.0           NaN   \n",
       "18          19                 5.0              3.0           NaN   \n",
       "22          23                 8.0              9.0           NaN   \n",
       "\n",
       "    StackOverflowSatisfaction    Salary  ExpectedSalary  \\\n",
       "2                         8.0  113750.0             NaN   \n",
       "14                        8.0  100000.0             NaN   \n",
       "17                        8.0  130000.0             NaN   \n",
       "18                        NaN   82500.0             NaN   \n",
       "22                        8.0  100764.0             NaN   \n",
       "\n",
       "    ProgramHobby_Yes, I contribute to open source projects  \\\n",
       "2                                                   0        \n",
       "14                                                  0        \n",
       "17                                                  0        \n",
       "18                                                  0        \n",
       "22                                                  0        \n",
       "\n",
       "    ProgramHobby_Yes, I program as a hobby  ProgramHobby_Yes, both  ...  \\\n",
       "2                                        0                       1  ...   \n",
       "14                                       1                       0  ...   \n",
       "17                                       0                       1  ...   \n",
       "18                                       1                       0  ...   \n",
       "22                                       0                       0  ...   \n",
       "\n",
       "    QuestionsInteresting_Strongly agree  \\\n",
       "2                                     0   \n",
       "14                                    0   \n",
       "17                                    0   \n",
       "18                                    0   \n",
       "22                                    0   \n",
       "\n",
       "    QuestionsInteresting_Strongly disagree  QuestionsConfusing_Disagree  \\\n",
       "2                                        0                            1   \n",
       "14                                       0                            1   \n",
       "17                                       0                            1   \n",
       "18                                       0                            0   \n",
       "22                                       0                            0   \n",
       "\n",
       "    QuestionsConfusing_Somewhat agree  QuestionsConfusing_Strongly agree  \\\n",
       "2                                   0                                  0   \n",
       "14                                  0                                  0   \n",
       "17                                  0                                  0   \n",
       "18                                  0                                  0   \n",
       "22                                  1                                  0   \n",
       "\n",
       "    QuestionsConfusing_Strongly disagree  InterestedAnswers_Disagree  \\\n",
       "2                                      0                           0   \n",
       "14                                     0                           0   \n",
       "17                                     0                           0   \n",
       "18                                     0                           0   \n",
       "22                                     0                           0   \n",
       "\n",
       "    InterestedAnswers_Somewhat agree  InterestedAnswers_Strongly agree  \\\n",
       "2                                  0                                 0   \n",
       "14                                 0                                 0   \n",
       "17                                 0                                 0   \n",
       "18                                 0                                 0   \n",
       "22                                 0                                 0   \n",
       "\n",
       "    InterestedAnswers_Strongly disagree  \n",
       "2                                     0  \n",
       "14                                    0  \n",
       "17                                    0  \n",
       "18                                    0  \n",
       "22                                    0  \n",
       "\n",
       "[5 rows x 11938 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Respondent                              9245.041525\n",
       "CareerSatisfaction                         7.534907\n",
       "JobSatisfaction                            7.024825\n",
       "HoursPerWeek                               2.447415\n",
       "StackOverflowSatisfaction                  8.442686\n",
       "                                           ...     \n",
       "QuestionsConfusing_Strongly disagree       0.256938\n",
       "InterestedAnswers_Disagree                 0.014973\n",
       "InterestedAnswers_Somewhat agree           0.082252\n",
       "InterestedAnswers_Strongly agree           0.401877\n",
       "InterestedAnswers_Strongly disagree        0.006588\n",
       "Length: 11938, dtype: float64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6\n",
    "\n",
    "**6.** Use the document string below to complete the function.  Then test your function against the solution.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_fit_linear_mod(df, response_col, cat_cols, dummy_na=False, test_size=.3, rand_state=42):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - a dataframe holding all the variables of interest\n",
    "    response_col - a string holding the name of the column \n",
    "    cat_cols - list of strings that are associated with names of the categorical columns\n",
    "    dummy_na - Bool holding whether you want to dummy NA vals of categorical columns or not\n",
    "    test_size - a float between [0,1] about what proportion of data should be in the test dataset\n",
    "    rand_state - an int that is provided as the random state for splitting the data into training and test \n",
    "    \n",
    "    OUTPUT:\n",
    "    test_score - float - r2 score on the test data\n",
    "    train_score - float - r2 score on the test data\n",
    "    lm_model - model object from sklearn\n",
    "    X_train, X_test, y_train, y_test - output from sklearn train test split used for optimal model\n",
    "    \n",
    "    Your function should:\n",
    "    1. Drop the rows with missing response values\n",
    "    2. Drop columns with NaN for all the values\n",
    "    3. Use create_dummy_df to dummy categorical columns\n",
    "    4. Fill the mean of the column for any missing values \n",
    "    5. Split your data into an X matrix and a response vector y\n",
    "    6. Create training and test sets of data\n",
    "    7. Instantiate a LinearRegression model with normalized data\n",
    "    8. Fit your model to the training data\n",
    "    9. Predict the response for the training data and the test data\n",
    "    10. Obtain an rsquared value for both the training and test data\n",
    "    '''\n",
    "    \n",
    "    df.dropna(axis=0, how='any', subset=[response_col], inplace=True)\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "    create_dummy_df(df, cat_cols, dummy_na=dummy_na)\n",
    "    df.fillna(df.mean(), inplace=True, axis=0)\n",
    "    \n",
    "    y = df[response_col]\n",
    "    X = df.drop(columns=[response_col], axis=1)\n",
    "    \n",
    "    #Split into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=rand_state) \n",
    "\n",
    "    lm_model = LinearRegression(normalize=True) # Instantiate\n",
    "    lm_model.fit(X_train, y_train) #Fit\n",
    "        \n",
    "    #Predict and score the model\n",
    "    y_train_preds = lm_model.predict(X_train)\n",
    "    y_test_preds = lm_model.predict(X_test)\n",
    "    \n",
    "    train_score = r2_score(y_train, y_train_preds)\n",
    "    test_score = r2_score(y_test, y_test_preds)\n",
    "    \n",
    "\n",
    "    return test_score, train_score, lm_model, X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['ExCoderBalance', 'ExCoderWillNotCode', 'NonDeveloperType', 'ExCoderBelonged', 'ExCoderNotForMe', 'ExCoderActive'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-203-d6abce94ab74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlm_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_fit_linear_mod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Salary'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_cols_lst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrand_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-202-c4851c472930>\u001b[0m in \u001b[0;36mclean_fit_linear_mod\u001b[1;34m(df, response_col, cat_cols, dummy_na, test_size, rand_state)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'any'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresponse_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mcreate_dummy_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdummy_na\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-201-f61adb2fb165>\u001b[0m in \u001b[0;36mcreate_dummy_df\u001b[1;34m(df, cat_cols, dummy_na)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;36m5.\u001b[0m \u001b[0mUse\u001b[0m \u001b[0ma\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0man\u001b[0m \u001b[0munderscore\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mseparating\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     '''\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mdf_cat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcat_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mdf_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcat_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mdf_cat_dummy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_cat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcat_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix_sep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdummy_na\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcat_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2984\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2986\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1283\u001b[0m                 \u001b[1;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"raise_missing\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1092\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m         )\n\u001b[0;32m   1094\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"loc\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not in index\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[1;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['ExCoderBalance', 'ExCoderWillNotCode', 'NonDeveloperType', 'ExCoderBelonged', 'ExCoderNotForMe', 'ExCoderActive'] not in index\""
     ]
    }
   ],
   "source": [
    "test_score, train_score, lm_model, X_train, X_test, y_train, y_test = clean_fit_linear_mod(df, 'Salary', cat_cols_lst, dummy_na=False, test_size=.3, rand_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-62c31205becc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Print training and testing score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The rsquared on the training data was {}.  The rsquared on the test data was {}.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_score' is not defined"
     ]
    }
   ],
   "source": [
    "#Print training and testing score\n",
    "print(\"The rsquared on the training data was {}.  The rsquared on the test data was {}.\".format(train_score, test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how much higher the rsquared value is on the training data than it is on the test data - why do you think that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_fit_linear_mod(df, response_col, cat_cols, dummy_na, test_size=.3, rand_state=42):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - a dataframe holding all the variables of interest\n",
    "    response_col - a string holding the name of the column \n",
    "    cat_cols - list of strings that are associated with names of the categorical columns\n",
    "    dummy_na - Bool holding whether you want to dummy NA vals of categorical columns or not\n",
    "    test_size - a float between [0,1] about what proportion of data should be in the test dataset\n",
    "    rand_state - an int that is provided as the random state for splitting the data into training and test \n",
    "    \n",
    "    OUTPUT:\n",
    "    test_score - float - r2 score on the test data\n",
    "    train_score - float - r2 score on the test data\n",
    "    lm_model - model object from sklearn\n",
    "    X_train, X_test, y_train, y_test - output from sklearn train test split used for optimal model\n",
    "    \n",
    "    Your function should:\n",
    "    1. Drop the rows with missing response values\n",
    "    2. Drop columns with NaN for all the values\n",
    "    3. Use create_dummy_df to dummy categorical columns\n",
    "    4. Fill the mean of the column for any missing values \n",
    "    5. Split your data into an X matrix and a response vector y\n",
    "    6. Create training and test sets of data\n",
    "    7. Instantiate a LinearRegression model with normalized data\n",
    "    8. Fit your model to the training data\n",
    "    9. Predict the response for the training data and the test data\n",
    "    10. Obtain an rsquared value for both the training and test data\n",
    "    '''\n",
    "    #Dropping where the salary has missing values\n",
    "    df = df.dropna(subset=[response_col], axis=0)\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "        \n",
    "    df = create_dummy_df(df, cat_cols, dummy_na = False)\n",
    "    df = df.fillna(df.mean())\n",
    "    \n",
    "    #Split into explanatory and response variables\n",
    "    X = df.drop(columns = response_col, axis=1)\n",
    "    y = df[response_col]\n",
    "\n",
    "    #Split into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state=rand_state) \n",
    "\n",
    "    lm_model = LinearRegression(normalize=True) # Instantiate\n",
    "    lm_model.fit(X_train, y_train) #Fit\n",
    "    \n",
    "    #Predict and score\n",
    "    y_train_preds = lm_model.predict(X_train) \n",
    "    y_test_preds = lm_model.predict(X_test) \n",
    "  \n",
    "    # test_score - float - r2 score\n",
    "    test_score = r2_score(y_test, y_test_preds)\n",
    "    train_score = r2_score(y_train, y_train_preds)\n",
    "    \n",
    "    return test_score, train_score, lm_model, X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
